{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "\n# nb26: G1 Bridge Verification — (O,R,α) → c\n\n**Purpose:** Empirically verify which candidate bridge form correctly maps Eckert Manifold\nvoid coordinates (O,R,α) to THRML constraint level c.\n\n**Three candidates (V1/V2 derived in §10D; V3 emerged from empirical failure of product forms):**\n- **V1 (Product form):** c = (1−O)(1−R)(1−α)\n- **V2 (Ratio form):** c = F_c / (F_c + F_v)\n- **V3 (Linear form):** c = 1 − (O+R+α)/9 = 1 − V/9  ← **winner**\n\n**Test data:**\n- 9 behavioral substrates with THRML-calibrated c from nb10\n- 8 market microstructure venues with c_kyle from nb25\n- N=17 total data points, spanning two independent measurement methods\n\n**Result:** V3 wins decisively — Spearman=0.910, RMSE=0.066 (vs V1/V2 RMSE=0.19–0.28).\nProduct forms (V1/V2) collapse to c≈0 whenever any dimension is at maximum, which is empirically wrong.\nThe additive structure of V3 is consistent with the Fantasia Bound conjugacy.\n\n**Closes:** G1 (V→THRML bridge) and G4 (independent c measurement) simultaneously.\n**Active bridge:** c = 1 − V/9  where V = O + R + α  (void index, 0–9 scale)\n"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "from scipy.stats import spearmanr, pearsonr\n",
    "from scipy.optimize import brentq\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Canonical THRML parameters\n",
    "b_alpha = 0.867\n",
    "b_gamma = 2.244\n",
    "c_zero  = b_alpha / b_gamma   # 0.3866 — K-invariant Pe=0 boundary\n",
    "K       = 16\n",
    "\n",
    "def pe_from_c(c, K=16):\n",
    "    b_net = b_gamma * c - b_alpha\n",
    "    return K * np.sinh(2 * b_net)\n",
    "\n",
    "print(f\"Canonical params: b_α={b_alpha}, b_γ={b_gamma}\")\n",
    "print(f\"c_zero = {c_zero:.4f}  (Pe=0 boundary, K-invariant)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Substrate scoring table\n",
    "\n",
    "Each substrate is scored on (O, R, α) using the standard void rubric (0–3 per dimension,\n",
    "then normalised to [0,1] by dividing by 3). Scores are based on platform architecture, not\n",
    "user behaviour — they are properties of the system design.\n",
    "\n",
    "**Rubric:**\n",
    "- **O (Opacity):** 0 = fully transparent mechanism; 3 = fully opaque (algorithm unknown)\n",
    "- **R (Responsiveness):** 0 = invariant/rule-bound; 3 = highly personalised/reactive\n",
    "- **α (Engagement coupling):** 0 = fully independent; 3 = deeply coupled (exits costly)\n",
    "\n",
    "**THRML-calibrated c (ground truth from nb07/nb10):**\n",
    "Inferred from empirical θ* equilibria — the c that matches observed engagement levels\n",
    "given canonical (b_α, b_γ). These are the values we are trying to predict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ─────────────────────────────────────────────────────────────────────────────\n",
    "# PART A: Behavioural substrates — calibrated c from nb10\n",
    "# ─────────────────────────────────────────────────────────────────────────────\n",
    "# (name, O_raw, R_raw, alpha_raw, c_thrml, source)\n",
    "# O/R/alpha on 0-3 scale; c_thrml from nb10 Table 1\n",
    "\n",
    "behavioral = [\n",
    "    # name,              O,  R,  a,   c_thrml\n",
    "    (\"AI-GG (governed)\",  1,  2,  2,   0.376),   # SOUL.md grounding: moderate O, responsive, engaged\n",
    "    (\"AI-UU (ungov.)\",    3,  3,  3,   0.030),   # No constraint: max void\n",
    "    (\"Gambling-Lo\",       2,  1,  2,   0.340),   # Slot machine: opaque RNG, low personalisation\n",
    "    (\"Gambling-RE\",       2,  2,  2,   0.356),   # Regular engagement gambling\n",
    "    (\"Gambling-Hi\",       2,  2,  3,   0.362),   # High-engagement gambling (VIP)\n",
    "    (\"ETH (DeFi active)\", 2,  2,  2,   0.335),   # Smart contracts visible but complex; reactive AMM\n",
    "    (\"Base DEX\",          2,  2,  2,   0.293),   # Similar architecture; lower liquidity anchor\n",
    "    (\"Solana DEX\",        2,  2,  3,   0.187),   # High-speed, high-engagement; more opaque MEV\n",
    "    (\"DEG (meme)\",        3,  3,  3,   0.108),   # Meme token: max opacity, max responsiveness, max coupling\n",
    "]\n",
    "\n",
    "# ─────────────────────────────────────────────────────────────────────────────\n",
    "# PART B: Market microstructure venues — c_kyle from nb25\n",
    "# c_kyle = sigma_u^2 / (sigma_v^2 + sigma_u^2)\n",
    "# Scored on void rubric: O=market opacity, R=order-flow responsiveness, alpha=trading coupling\n",
    "# ─────────────────────────────────────────────────────────────────────────────\n",
    "\n",
    "# c_kyle values from nb25 Table: venues ordered Vanguard → meme coin\n",
    "# sigma_u = uninformed order std, sigma_v = informed order std\n",
    "# c_kyle = sigma_u^2 / (sigma_u^2 + sigma_v^2)\n",
    "\n",
    "microstructure = [\n",
    "    # name,                 O,  R,  a,   c_kyle   (from nb25)\n",
    "    (\"Vanguard index\",      0,  0,  1,   0.870),  # Transparent NAV; invariant rules; low coupling\n",
    "    (\"NYSE lit book\",       1,  1,  2,   0.620),  # Visible order book; rule-bound MM; moderate coupling\n",
    "    (\"NASDAQ lit\",          1,  2,  2,   0.520),  # Visible but faster/more reactive than NYSE\n",
    "    (\"Dark pool\",           3,  1,  2,   0.350),  # Fully opaque; rule-bound internally; moderate coupling\n",
    "    (\"Crypto CEX\",          2,  2,  3,   0.280),  # Partial transparency; responsive order book; high coupling\n",
    "    (\"Crypto DEX\",          2,  3,  3,   0.190),  # AMM formula visible but complex; highly reactive; high coupling\n",
    "    (\"OTC derivatives\",     3,  2,  3,   0.120),  # Opaque bespoke; negotiated; high commitment\n",
    "    (\"Meme coin OTC\",       3,  3,  3,   0.055),  # Max opacity, max responsiveness, max coupling\n",
    "]\n",
    "\n",
    "# Combine\n",
    "all_substrates = behavioral + microstructure\n",
    "names   = [s[0] for s in all_substrates]\n",
    "O_raw   = np.array([s[1] for s in all_substrates], dtype=float)\n",
    "R_raw   = np.array([s[2] for s in all_substrates], dtype=float)\n",
    "a_raw   = np.array([s[3] for s in all_substrates], dtype=float)\n",
    "c_true  = np.array([s[4] for s in all_substrates], dtype=float)\n",
    "is_micro = np.array([False]*len(behavioral) + [True]*len(microstructure))\n",
    "\n",
    "# Normalise to [0,1]\n",
    "O = O_raw / 3.0\n",
    "R = R_raw / 3.0\n",
    "a = a_raw / 3.0\n",
    "\n",
    "print(f\"N = {len(all_substrates)} substrates ({len(behavioral)} behavioural + {len(microstructure)} market)\")\n",
    "print(f\"c_true range: [{c_true.min():.3f}, {c_true.max():.3f}]\")\n",
    "print(f\"c_zero = {c_zero:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 2. Apply bridge forms V1, V2, and V3"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# V1: Product form\n",
    "def v1_bridge(O, R, a):\n",
    "    return (1 - O) * (1 - R) * (1 - a)\n",
    "\n",
    "# V2: Ratio / force-balance form (equal gamma=beta prior)\n",
    "# F_constraint = (1-O)(1-R)(1-a), F_void = O*R*a\n",
    "# c = F_c / (F_c + F_v)\n",
    "def v2_bridge(O, R, a, eps=1e-12):\n",
    "    Fc = (1 - O) * (1 - R) * (1 - a)\n",
    "    Fv = O * R * a\n",
    "    return Fc / (Fc + Fv + eps)\n",
    "\n",
    "c_v1 = v1_bridge(O, R, a)\n",
    "c_v2 = v2_bridge(O, R, a)\n",
    "\n",
    "# Pe predictions from each bridge\n",
    "pe_v1   = pe_from_c(c_v1)\n",
    "pe_v2   = pe_from_c(c_v2)\n",
    "pe_true = pe_from_c(c_true)\n",
    "\n",
    "print(\"Substrate            O    R    α  | c_true  c_V1   c_V2  | Pe_true  Pe_V1  Pe_V2\")\n",
    "print(\"-\" * 90)\n",
    "for i, name in enumerate(names):\n",
    "    tag = \"[M]\" if is_micro[i] else \"   \"\n",
    "    print(f\"{tag} {name:<22} {O_raw[i]:.0f}    {R_raw[i]:.0f}    {a_raw[i]:.0f}  \"\n",
    "          f\"| {c_true[i]:.3f}   {c_v1[i]:.3f}  {c_v2[i]:.3f}  \"\n",
    "          f\"| {pe_true[i]:7.2f}  {pe_v1[i]:6.2f}  {pe_v2[i]:6.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Statistical comparison: V1 vs V2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import spearmanr\n",
    "\n",
    "def bridge_stats(c_pred, c_true, label):\n",
    "    rho, p = spearmanr(c_pred, c_true)\n",
    "    rmse   = np.sqrt(np.mean((c_pred - c_true)**2))\n",
    "    mae    = np.mean(np.abs(c_pred - c_true))\n",
    "    # Pe-level Spearman (what actually matters for the framework)\n",
    "    pe_pred = pe_from_c(c_pred)\n",
    "    pe_t    = pe_from_c(c_true)\n",
    "    rho_pe, p_pe = spearmanr(pe_pred, pe_t)\n",
    "    print(f\"  {label}:\")\n",
    "    print(f\"    Spearman(c_pred, c_true)   = {rho:.4f}  (p={p:.4f})\")\n",
    "    print(f\"    Spearman(Pe_pred, Pe_true) = {rho_pe:.4f}  (p={p_pe:.4f})\")\n",
    "    print(f\"    RMSE(c)  = {rmse:.4f}\")\n",
    "    print(f\"    MAE(c)   = {mae:.4f}\")\n",
    "    return rho, rho_pe, rmse, mae\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(f\"FULL SAMPLE (N={len(all_substrates)})\")\n",
    "print(\"=\" * 60)\n",
    "r1, rp1, rmse1, mae1 = bridge_stats(c_v1, c_true, \"V1 (product)\")\n",
    "r2, rp2, rmse2, mae2 = bridge_stats(c_v2, c_true, \"V2 (ratio)  \")\n",
    "\n",
    "print()\n",
    "print(\"=\" * 60)\n",
    "print(f\"BEHAVIOURAL ONLY (N={len(behavioral)}) — in-sample (nb10 calibrated)\")\n",
    "print(\"=\" * 60)\n",
    "bridge_stats(c_v1[~is_micro], c_true[~is_micro], \"V1 (product)\")\n",
    "bridge_stats(c_v2[~is_micro], c_true[~is_micro], \"V2 (ratio)  \")\n",
    "\n",
    "print()\n",
    "print(\"=\" * 60)\n",
    "print(f\"MARKET MICROSTRUCTURE ONLY (N={len(microstructure)}) — out-of-sample (nb25 c_kyle)\")\n",
    "print(\"=\" * 60)\n",
    "bridge_stats(c_v1[is_micro], c_true[is_micro], \"V1 (product)\")\n",
    "bridge_stats(c_v2[is_micro], c_true[is_micro], \"V2 (ratio)  \")"
   ]
  },
  {
   "cell_type": "code",
   "source": "\n# ── V3: Linear bridge — emerged from data showing product forms collapse at max scores ──\n# V1 and V2 both use a product of (1-O)(1-R)(1-a) in the numerator.\n# When any single dimension = 3 (max), this product = 0, forcing c_pred = 0.\n# But empirically c_true >> 0 for many such substrates (Gambling-Hi c=0.362, Crypto CEX c=0.280).\n# This means the product form is wrong: individual dimensions don't independently zero-out constraint.\n# The actual relationship is ADDITIVE — each dimension contributes equally.\n#\n# V3 (Linear form): c = 1 - (O + R + α) / 9 = 1 - V/9\n# where V = O + R + α is the standard void index (0-9 scale).\n# This is the simplest possible bridge and it turns out to be the best.\n\ndef v3_bridge(O_raw, R_raw, a_raw):\n    V = O_raw + R_raw + a_raw   # void index on 0-9 scale\n    return 1 - V / 9.0\n\nc_v3 = v3_bridge(O_raw, R_raw, a_raw)\nV_raw = O_raw + R_raw + a_raw\n\n# Stats\nr3, p3 = spearmanr(c_v3, c_true)\nrmse3  = np.sqrt(np.mean((c_v3 - c_true)**2))\nmae3   = np.mean(np.abs(c_v3 - c_true))\nrho_pe3, _ = spearmanr(pe_from_c(c_v3), pe_from_c(c_true))\n\nprint(\"=\" * 60)\nprint(\"V3 LINEAR BRIDGE:  c = 1 − (O + R + α) / 9\")\nprint(\"=\" * 60)\nprint(f\"  Spearman(c)  = {r3:.4f}  (p={p3:.6f})\")\nprint(f\"  Spearman(Pe) = {rho_pe3:.4f}\")\nprint(f\"  RMSE(c)      = {rmse3:.4f}\")\nprint(f\"  MAE(c)       = {mae3:.4f}\")\nprint()\n\n# Pe=0 and Pe=1 boundaries in void score space\nV_zero  = 9 * (1 - c_zero)\nV_crit  = brentq(lambda V: pe_from_c(1 - V/9) - 0, 0.1, 8.9)   # Pe=0\nprint(f\"Pe=0 boundary:  V* = {V_zero:.2f}/9  (void score at which Pe changes sign)\")\nprint(f\"  → platforms with void score > {V_zero:.1f}/9 are drift-dominated (Pe > 0)\")\nprint()\n\n# Substrate table\nprint(f\"{'Substrate':<20} {'V/9':>4}  {'c_true':>7}  {'c_V3':>7}  {'error':>8}\")\nprint(\"-\" * 55)\nfor i, name in enumerate(names):\n    tag = \"[M]\" if is_micro[i] else \"   \"\n    err = c_v3[i] - c_true[i]\n    print(f\"{tag}{name:<20} {V_raw[i]/9:.3f}  {c_true[i]:>7.3f}  {c_v3[i]:>7.3f}  {err:>+8.3f}\")\n\nprint()\nprint(\"Comparison summary:\")\nprint(f\"  V1 (product): Spearman={r1:.4f}  RMSE={rmse1:.4f}\")\nprint(f\"  V2 (ratio):   Spearman={r2:.4f}  RMSE={rmse2:.4f}\")\nprint(f\"  V3 (linear):  Spearman={r3:.4f}  RMSE={rmse3:.4f}  ← winner\")\nprint(f\"  RMSE improvement V3 over V2: {(rmse2-rmse3)/rmse2*100:.1f}%\")\nprint(f\"  RMSE improvement V3 over V1: {(rmse1-rmse3)/rmse1*100:.1f}%\")\n",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Where V1 and V2 diverge\n",
    "\n",
    "The two forms agree at the poles (all-void, all-constrained) and diverge at intermediate\n",
    "coordinates. This cell identifies which substrates show the largest V1 vs V2 disagreement\n",
    "and what the Pe implications are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divergence analysis\n",
    "delta_c  = np.abs(c_v1 - c_v2)\n",
    "delta_pe = np.abs(pe_v1 - pe_v2)\n",
    "\n",
    "# Sort by divergence\n",
    "idx = np.argsort(delta_c)[::-1]\n",
    "print(\"Substrates by V1/V2 disagreement (largest first):\")\n",
    "print(f\"{'Substrate':<25} {'Δc':>6}  {'ΔPe':>8}  {'c_V1':>6}  {'c_V2':>6}  {'c_true':>7}  {'V1 closer':>10}\")\n",
    "print(\"-\" * 80)\n",
    "for i in idx:\n",
    "    v1_closer = \"V1\" if abs(c_v1[i]-c_true[i]) < abs(c_v2[i]-c_true[i]) else \"V2\"\n",
    "    print(f\"{names[i]:<25} {delta_c[i]:>6.3f}  {delta_pe[i]:>8.2f}  \"\n",
    "          f\"{c_v1[i]:>6.3f}  {c_v2[i]:>6.3f}  {c_true[i]:>7.3f}  {v1_closer:>10}\")\n",
    "\n",
    "# Pe=0 boundary predictions\n",
    "print()\n",
    "print(\"Pe=0 boundary predictions:\")\n",
    "x_v1 = 1 - c_zero**(1/3)\n",
    "# V2 Pe=0: (1-x)^3 / ((1-x)^3 + x^3) = c_zero\n",
    "f_v2 = lambda x: (1-x)**3 / ((1-x)**3 + x**3 + 1e-12) - c_zero\n",
    "x_v2 = brentq(f_v2, 0.01, 0.99)\n",
    "print(f\"  V1: equal-dimension void score x* = {x_v1:.3f}  ({x_v1*3:.2f}/3 per dimension, {x_v1*9:.2f}/9 total)\")\n",
    "print(f\"  V2: equal-dimension void score x* = {x_v2:.3f}  ({x_v2*3:.2f}/3 per dimension, {x_v2*9:.2f}/9 total)\")\n",
    "print(f\"  Difference: {abs(x_v1-x_v2):.3f} in normalized coords = {abs(x_v1-x_v2)*3:.2f} void points per dimension\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Figures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "\n# ── Figure 1: Predicted vs calibrated c for all three bridge forms ──────────\nfig, axes = plt.subplots(1, 3, figsize=(16, 5))\nfig.patch.set_facecolor('#0a0a0f')\ncolors = {'behav': '#6366f1', 'micro': '#22d3ee'}\n\nfor ax, c_pred, rho, rmse, label in [\n    (axes[0], c_v1, r1, rmse1, f'V1 (product)\\nρ={r1:.3f}  RMSE={rmse1:.3f}'),\n    (axes[1], c_v2, r2, rmse2, f'V2 (ratio)\\nρ={r2:.3f}  RMSE={rmse2:.3f}'),\n    (axes[2], c_v3, r3, rmse3, f'V3 (linear)  ← WINNER\\nρ={r3:.3f}  RMSE={rmse3:.3f}'),\n]:\n    ax.set_facecolor('#111118')\n    diag = np.linspace(0, 1, 100)\n    ax.plot(diag, diag, '--', color='#374151', lw=1, alpha=0.6, label='perfect')\n    ax.axvline(c_zero, color='#ef4444', lw=0.8, alpha=0.4, linestyle=':')\n    ax.axhline(c_zero, color='#ef4444', lw=0.8, alpha=0.4, linestyle=':')\n\n    for i in range(len(all_substrates)):\n        col = colors['micro'] if is_micro[i] else colors['behav']\n        ax.scatter(c_pred[i], c_true[i], color=col, s=60, zorder=5,\n                   alpha=0.85, edgecolors='white', linewidth=0.3)\n        if abs(c_pred[i] - c_true[i]) > 0.08:\n            ax.annotate(names[i].split('(')[0].strip(),\n                        (c_pred[i], c_true[i]),\n                        textcoords='offset points', xytext=(4, 3),\n                        fontsize=6, color='#9ca3af')\n\n    ax.set_xlabel('c predicted', color='#9ca3af', fontsize=9)\n    ax.set_ylabel('c calibrated (THRML / Kyle)', color='#9ca3af', fontsize=9)\n    ax.set_title(label, color='#e2e8f0', fontsize=9, pad=8)\n    ax.tick_params(colors='#6b7280')\n    for spine in ax.spines.values():\n        spine.set_edgecolor('#1e1e2e')\n    ax.text(0.02, 0.97, 'Pe=0', color='#ef4444', fontsize=7,\n            transform=ax.transAxes, va='top', alpha=0.7)\n\n# Highlight winner\naxes[2].patch.set_facecolor('#111820')\n\nhandles = [\n    mpatches.Patch(color=colors['behav'], label='Behavioural (nb10)'),\n    mpatches.Patch(color=colors['micro'], label='Market micro. (nb25)'),\n]\nfig.legend(handles=handles, loc='lower center', ncol=2, fontsize=9,\n           facecolor='#111118', edgecolor='#1e1e2e', labelcolor='#9ca3af',\n           bbox_to_anchor=(0.5, -0.04))\nplt.suptitle('G1 Bridge: Predicted vs Calibrated c  (N=17)', color='#e2e8f0',\n             fontsize=12, y=1.02)\nplt.tight_layout()\nplt.savefig('nb26_bridge_predicted_vs_calibrated.svg', bbox_inches='tight',\n            facecolor='#0a0a0f', dpi=150)\nplt.show()\nprint(\"Saved: nb26_bridge_predicted_vs_calibrated.svg\")\n"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "\n# ── Figure 2: Bridge surface along equal-dimension diagonal (all 3 forms) ───\nx_vals = np.linspace(0, 1, 300)\nc_v1_diag = (1 - x_vals)**3\nc_v2_diag = (1 - x_vals)**3 / ((1 - x_vals)**3 + x_vals**3 + 1e-12)\nc_v3_diag = 1 - x_vals          # V3: c = 1 - V/9 along O=R=α diagonal (x = dim/3)\npe_v1_diag = pe_from_c(c_v1_diag)\npe_v2_diag = pe_from_c(c_v2_diag)\npe_v3_diag = pe_from_c(c_v3_diag)\n\nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=(13, 5))\nfig.patch.set_facecolor('#0a0a0f')\n\nfor ax in [ax1, ax2]:\n    ax.set_facecolor('#111118')\n    ax.tick_params(colors='#6b7280')\n    for spine in ax.spines.values():\n        spine.set_edgecolor('#1e1e2e')\n\n# c vs x — all 3 forms\nax1.plot(x_vals * 3, c_v1_diag, color='#6366f1', lw=2, label='V1 product  c=(1−x)³')\nax1.plot(x_vals * 3, c_v2_diag, color='#22d3ee', lw=2, label='V2 ratio    c=(1−x)³/[(1−x)³+x³]')\nax1.plot(x_vals * 3, c_v3_diag, color='#f59e0b', lw=2.5, linestyle='-',\n         label='V3 linear  c=1−x  ← WINNER')\nax1.axhline(c_zero, color='#ef4444', lw=1, linestyle='--', alpha=0.7,\n            label=f'c_zero={c_zero:.4f}')\n# Pe=0 boundaries\nax1.axvline(x_v1 * 3, color='#6366f1', lw=0.8, linestyle=':', alpha=0.5)\nax1.axvline(x_v2 * 3, color='#22d3ee', lw=0.8, linestyle=':', alpha=0.5)\nV_star = 9 * (1 - c_zero)          # V3 Pe=0 boundary in void index units\nax1.axvline(V_star / 3, color='#f59e0b', lw=0.8, linestyle=':', alpha=0.5)\nax1.set_xlabel('Void score per dimension (0–3)', color='#9ca3af')\nax1.set_ylabel('c (constraint level)', color='#9ca3af')\nax1.set_title('Bridge surface — O=R=α diagonal', color='#e2e8f0')\nax1.legend(fontsize=8, facecolor='#111118', edgecolor='#1e1e2e', labelcolor='#9ca3af')\nax1.set_xlim(0, 3)\n\n# Overlay substrates (mean dimension as x)\nvoid_score_eq = (O_raw + R_raw + a_raw) / 3\nfor i in range(len(all_substrates)):\n    col = '#22d3ee' if is_micro[i] else '#6366f1'\n    ax1.scatter(void_score_eq[i], c_true[i], color=col, s=40, zorder=6,\n                edgecolors='white', linewidth=0.3, alpha=0.9)\n\n# Pe vs x\nax2.plot(x_vals * 3, pe_v1_diag, color='#6366f1', lw=2, label='V1')\nax2.plot(x_vals * 3, pe_v2_diag, color='#22d3ee', lw=2, label='V2')\nax2.plot(x_vals * 3, pe_v3_diag, color='#f59e0b', lw=2.5, label='V3 ← WINNER')\nax2.axhline(0, color='#ef4444', lw=1, linestyle='--', alpha=0.7, label='Pe=0')\nax2.axhline(1, color='#9ca3af', lw=0.8, linestyle=':', alpha=0.5)\nax2.axvline(V_star / 3, color='#f59e0b', lw=0.8, linestyle=':', alpha=0.5)\nfor i in range(len(all_substrates)):\n    col = '#22d3ee' if is_micro[i] else '#6366f1'\n    ax2.scatter(void_score_eq[i], pe_true[i], color=col, s=40, zorder=6,\n                edgecolors='white', linewidth=0.3, alpha=0.9)\nax2.set_xlabel('Void score per dimension (0–3)', color='#9ca3af')\nax2.set_ylabel('Pe (Péclet number)', color='#9ca3af')\nax2.set_title('Implied Pe — O=R=α diagonal', color='#e2e8f0')\nax2.legend(fontsize=8, facecolor='#111118', edgecolor='#1e1e2e', labelcolor='#9ca3af')\nax2.set_xlim(0, 3)\nax2.set_ylim(-5, 30)\n\nplt.suptitle('G1 Bridge: V1 / V2 / V3 along equal-dimension diagonal', color='#e2e8f0',\n             fontsize=12, y=1.02)\nplt.tight_layout()\nplt.savefig('nb26_bridge_surface_comparison.svg', bbox_inches='tight',\n            facecolor='#0a0a0f', dpi=150)\nplt.show()\nprint(\"Saved: nb26_bridge_surface_comparison.svg\")\n"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "\n# ── Figure 3: Residuals by substrate — all three forms ──────────────────────\nerr_v1 = c_v1 - c_true\nerr_v2 = c_v2 - c_true\nerr_v3 = c_v3 - c_true\norder  = np.argsort(c_true)   # sort by calibrated c ascending\n\nfig, ax = plt.subplots(figsize=(14, 5))\nfig.patch.set_facecolor('#0a0a0f')\nax.set_facecolor('#111118')\n\nx_pos = np.arange(len(all_substrates))\nw = 0.25\nax.bar(x_pos - w, err_v1[order], w, color='#6366f1', alpha=0.8, label='V1 (product)')\nax.bar(x_pos,     err_v2[order], w, color='#22d3ee', alpha=0.8, label='V2 (ratio)')\nax.bar(x_pos + w, err_v3[order], w, color='#f59e0b', alpha=0.9, label='V3 (linear) ← WINNER')\nax.axhline(0, color='#e2e8f0', lw=0.8, alpha=0.5)\n\nshort_names = [n.split('(')[0].strip()[:14] for n in names]\nax.set_xticks(x_pos)\nax.set_xticklabels([short_names[i] for i in order], rotation=45, ha='right',\n                   fontsize=7.5, color='#9ca3af')\nax.set_ylabel('c_pred − c_true', color='#9ca3af')\nax.set_title('G1 Bridge Residuals — V1 / V2 / V3 by Substrate (sorted by c_true ascending)',\n             color='#e2e8f0', fontsize=11)\nax.tick_params(colors='#6b7280')\nfor spine in ax.spines.values():\n    spine.set_edgecolor('#1e1e2e')\n\n# Shade market micro substrates\nfor i, orig_idx in enumerate(order):\n    if is_micro[orig_idx]:\n        ax.axvspan(i - 0.5, i + 0.5, alpha=0.07, color='#22d3ee')\n\n# RMSE annotation\nax.text(0.01, 0.97,\n        f'RMSE:  V1={rmse1:.3f}   V2={rmse2:.3f}   V3={rmse3:.3f}',\n        transform=ax.transAxes, ha='left', va='top',\n        fontsize=8.5, color='#e2e8f0',\n        bbox=dict(facecolor='#1e1e2e', edgecolor='none', alpha=0.7, pad=3))\n\nax.legend(fontsize=9, facecolor='#111118', edgecolor='#1e1e2e', labelcolor='#9ca3af',\n          loc='upper right')\nax.text(0.99, 0.02, 'Shaded = market microstructure (nb25)',\n        transform=ax.transAxes, ha='right', va='bottom',\n        fontsize=7, color='#22d3ee', alpha=0.7)\n\nplt.tight_layout()\nplt.savefig('nb26_bridge_residuals.svg', bbox_inches='tight',\n            facecolor='#0a0a0f', dpi=150)\nplt.show()\nprint(\"Saved: nb26_bridge_residuals.svg\")\n"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Synthesis and falsifiable predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "\n# ── Three-way comparison including V3 ────────────────────────────────────────\n# V3 results computed in cell 8\nprint(\"═\" * 65)\nprint(\"G1 BRIDGE VERIFICATION SUMMARY\")\nprint(\"═\" * 65)\nprint(f\"  V1 (product):  Spearman={r1:.4f}  RMSE={rmse1:.4f}  MAE={mae1:.4f}\")\nprint(f\"  V2 (ratio):    Spearman={r2:.4f}  RMSE={rmse2:.4f}  MAE={mae2:.4f}\")\nprint(f\"  V3 (linear):   Spearman={r3:.4f}  RMSE={rmse3:.4f}  MAE={mae3:.4f}  ← WINNER\")\nprint()\nprint(f\"  V3 RMSE improvement over V2: {(rmse2 - rmse3)/rmse2 * 100:.1f}%\")\nprint(f\"  V3 RMSE improvement over V1: {(rmse1 - rmse3)/rmse1 * 100:.1f}%\")\nprint()\n\n# Winner is V3\nprint(\"  Verdict: V3 (LINEAR) PREFERRED\")\nprint(\"  c = 1 − (O + R + α) / 9  =  1 − V/9\")\nprint()\nprint(\"  Why V3 wins:\")\nprint(\"  - V1/V2 use product (1−O)(1−R)(1−α): any single dimension at max → c=0\")\nprint(\"  - Empirically wrong: Gambling-Hi (V=7/9) has c=0.362, not ≈0\")\nprint(\"  - V3 treats dimensions ADDITIVELY — each contributes equally to constraint erosion\")\nprint(\"  - Additive structure is consistent with the Fantasia Bound conjugacy\")\nprint()\n\n# Pe=0 boundary under V3\nV_star = 9 * (1 - c_zero)\nprint(f\"  Pe=0 boundary under V3: V* = {V_star:.2f}/9\")\nprint(f\"  → platforms with void index > {V_star:.1f}/9 are drift-dominated (Pe > 0)\")\nprint()\n\nprint(\"Falsifiable predictions (GB = G1 Bridge):\")\nprint(\"  GB-1: Spearman(c_V3, c_new) ≥ 0.85 on any 5 new scored substrates\")\nprint(\"  GB-2: Pe=0 boundary empirically at void score V* ≈ 5.52/9 (falsified if < 4 or > 7)\")\nprint(\"  GB-3: c_kyle (market venues, EXP-027 real LOBSTER data) Spearman ≥ 0.90 vs V3\")\nprint(\"  GB-4: G4 closure — c scored from (O,R,α) correlates ρ > 0.80 with c from θ*\")\nprint(f\"        [This notebook IS that test: Spearman(V3) = {r3:.4f}  →  G4 CLOSED ✓]\")\nprint()\n\n# G4 closure check\ng4_closed = r3 > 0.80\nprint(f\"G4 CLOSURE: Spearman(V3) = {r3:.4f}  →  {'CLOSED ✓' if g4_closed else 'NOT CLOSED'}\")\nif g4_closed:\n    print(\"  Independent measurement of c via (O,R,α) scoring is validated.\")\n    print(\"  Void scores predict THRML constraint level without θ* calibration.\")\nprint()\nprint(f\"Canonical K=16 unchanged — hardware parameter, not a void architecture property.\")\nprint(f\"G1 bridge: CLOSED.  G4 gap: CLOSED.  Active form: V3  c = 1 − V/9\")\n"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}